{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iv74AATNf2NI",
        "outputId": "04145920-b82c-40d1-f1fd-6f2cb0815b3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-04 20:35:59.583496: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-03-04 20:35:59.592810: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741109759.604060   34223 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741109759.607640   34223 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-04 20:35:59.620252: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch_xla/__init__.py:253: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['PJRT_DEVICE'] = 'CPU'\n",
        "\n",
        "import numpy as np\n",
        "import torch \n",
        "import tensorflow as tf\n",
        "import ai_edge_torch\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Prp4lBZDf2PY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.nn import Parameter\n",
        "import timm\n",
        "\n",
        "class SeparableConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False):\n",
        "        super(SeparableConv2d, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding, dilation, groups=in_channels,\n",
        "                                    bias=bias),\n",
        "                                    nn.BatchNorm2d(in_channels))\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, 1, 0, 1, 1, bias=bias)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pointwise(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def normal_init(module, mean=0, std=1, bias=0):\n",
        "        nn.init.normal_(module.weight, mean, std)\n",
        "        if hasattr(module, 'bias'):\n",
        "            nn.init.constant_(module.bias, bias)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ComplexUpsample(nn.Module):\n",
        "    def __init__(self, input_dim=128, outpt_dim=128):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(SeparableConv2d(input_dim, outpt_dim, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "                                   nn.BatchNorm2d(outpt_dim),\n",
        "                                   nn.ReLU(inplace=True)\n",
        "                                   )\n",
        "\n",
        "        self.conv2 = nn.Sequential(SeparableConv2d(input_dim, outpt_dim, kernel_size=5, stride=1, padding=2, bias=False),\n",
        "                                   nn.BatchNorm2d(outpt_dim),\n",
        "                                   nn.ReLU(inplace=True)\n",
        "                                   )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # do preprocess\n",
        "\n",
        "        x = self.conv1(inputs)\n",
        "        y = self.conv2(inputs)\n",
        "\n",
        "        z = x + y\n",
        "\n",
        "        z = nn.functional.interpolate(z, scale_factor=2,mode='bilinear' )\n",
        "\n",
        "        return z\n",
        "\n",
        "class Fpn(nn.Module):\n",
        "    def __init__(self,input_dims=[24,32,96,320],head_dims=[128,128,128] ):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        self.latlayer2=nn.Sequential(SeparableConv2d(input_dims[0],head_dims[0]//2,kernel_size=5,padding=2),\n",
        "                                      nn.BatchNorm2d(head_dims[0]//2),\n",
        "                                      nn.ReLU(inplace=True))\n",
        "\n",
        "\n",
        "        self.latlayer3=nn.Sequential(SeparableConv2d(input_dims[1],head_dims[1]//2,kernel_size=5,padding=2),\n",
        "                                      nn.BatchNorm2d(head_dims[1]//2),\n",
        "                                      nn.ReLU(inplace=True))\n",
        "\n",
        "        self.latlayer4 = nn.Sequential(SeparableConv2d(input_dims[2], head_dims[2] // 2,kernel_size=5,padding=2),\n",
        "                                       nn.BatchNorm2d(head_dims[2] // 2),\n",
        "                                       nn.ReLU(inplace=True))\n",
        "\n",
        "\n",
        "\n",
        "        self.upsample3=ComplexUpsample(head_dims[1],head_dims[0]//2)\n",
        "\n",
        "        self.upsample4 =ComplexUpsample(head_dims[2],head_dims[1]//2)\n",
        "\n",
        "        self.upsample5 = ComplexUpsample(input_dims[3],head_dims[2]//2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        ##/24,32,96,320\n",
        "        c2, c3, c4, c5 = inputs\n",
        "\n",
        "        c4_lat = self.latlayer4(c4)\n",
        "        c3_lat = self.latlayer3(c3)\n",
        "        c2_lat = self.latlayer2(c2)\n",
        "\n",
        "\n",
        "        upsample_c5=self.upsample5(c5)\n",
        "\n",
        "        p4=torch.cat([c4_lat,upsample_c5],dim=1)\n",
        "\n",
        "\n",
        "        upsample_p4=self.upsample4(p4)\n",
        "\n",
        "        p3=torch.cat([c3_lat,upsample_p4],dim=1)\n",
        "\n",
        "        upsample_p3 = self.upsample3(p3)\n",
        "\n",
        "        p2 = torch.cat([c2_lat, upsample_p3],dim=1)\n",
        "\n",
        "\n",
        "        return p2\n",
        "\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super().__init__()\n",
        "        struct = 'Mobilenetv2'\n",
        "        if 'Mobilenetv2' in struct:\n",
        "            self.model = timm.create_model('mobilenetv2_100', pretrained=True, features_only=True,exportable=True)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # do preprocess\n",
        "\n",
        "        # Convolution layers\n",
        "        fms = self.model(inputs)\n",
        "\n",
        "        # for ff in fms:\n",
        "        #     print(ff.size())\n",
        "\n",
        "        return fms[-4:]\n",
        "\n",
        "class CenterNetHead(nn.Module):\n",
        "    def __init__(self,nc,head_dims=[128,128,128] ):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "\n",
        "        self.cls =SeparableConv2d(head_dims[0], nc, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        self.wh =SeparableConv2d(head_dims[0], 4, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        # self.offset =SeparableConv2d(head_dims[0], 2, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        # self.iou_head = nn.Conv2d(head_dims[0], 1, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "\n",
        "        normal_init(self.cls.pointwise, 0, 0.01,-2.19)\n",
        "        normal_init(self.wh.pointwise, 0, 0.01, 0)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "\n",
        "        cls = self.cls(inputs).sigmoid_()\n",
        "        wh = self.wh(inputs)\n",
        "        # offset = self.offset(inputs)\n",
        "        # iou_aware_head = self.iou_head(inputs).sigmoid_().squeeze(1) #[B, H, W]\n",
        "\n",
        "\n",
        "        return cls,wh\n",
        "\n",
        "class CenterNet(nn.Module):\n",
        "    def __init__(self,nc):\n",
        "        super().__init__()\n",
        "\n",
        "        self.nc = nc\n",
        "        self.down_ratio= 4\n",
        "\n",
        "\n",
        "        ###model structure\n",
        "        self.backbone = Net()\n",
        "\n",
        "        self.fpn=Fpn(head_dims=[128,192,256],input_dims=[24,32,96,320])\n",
        "\n",
        "        self.head = CenterNetHead(self.nc,head_dims=[128,192,256])\n",
        "\n",
        "\n",
        "\n",
        "        if self.down_ratio==8:\n",
        "            self.extra_conv=nn.Sequential(SeparableConv2d([24,32,96,320][-2],[24,32,96,320][-1],\n",
        "                                                    kernel_size=3,stride=2,padding=1),\n",
        "                                          nn.BatchNorm2d([24,32,96,320][-1]),\n",
        "                                          nn.ReLU(inplace=True))\n",
        "        else:\n",
        "            self.extra_conv=None\n",
        "\n",
        "\n",
        "\n",
        "        self.device=torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        fms = self.backbone(inputs)\n",
        "\n",
        "        if self.extra_conv is not None:\n",
        "\n",
        "            extra_fm=self.extra_conv(fms[-1])\n",
        "            fms.append(extra_fm)\n",
        "            fms=fms[1:]\n",
        "\n",
        "        fpn_fm=self.fpn(fms)\n",
        "\n",
        "        cls, wh = self.head(fpn_fm)\n",
        "\n",
        "\n",
        "\n",
        "        return cls,wh*16\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRa5oJY6korG",
        "outputId": "b606dc39-ac5d-4651-887f-6929d2237bef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:timm.models._builder:Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
          ]
        }
      ],
      "source": [
        "model = CenterNet(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXQRqPs5kott",
        "outputId": "0eeb2736-854a-4e6f-a7f7-0c87e3c63abf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CenterNet(\n",
              "  (backbone): Net(\n",
              "    (model): EfficientNetFeatures(\n",
              "      (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNormAct2d(\n",
              "        32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (drop): Identity()\n",
              "        (act): ReLU6(inplace=True)\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): Sequential(\n",
              "          (0): DepthwiseSeparableConv(\n",
              "            (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "            (bn1): BatchNormAct2d(\n",
              "              32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (aa): Identity()\n",
              "            (se): Identity()\n",
              "            (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn2): BatchNormAct2d(\n",
              "              16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): Identity()\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "        )\n",
              "        (1): Sequential(\n",
              "          (0): InvertedResidual(\n",
              "            (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNormAct2d(\n",
              "              96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "            (bn2): BatchNormAct2d(\n",
              "              96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (aa): Identity()\n",
              "            (se): Identity()\n",
              "            (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNormAct2d(\n",
              "              24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): Identity()\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (1): InvertedResidual(\n",
              "            (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNormAct2d(\n",
              "              144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "            (bn2): BatchNormAct2d(\n",
              "              144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (aa): Identity()\n",
              "            (se): Identity()\n",
              "            (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNormAct2d(\n",
              "              24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): Identity()\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "        )\n",
              "        (2): Sequential(\n",
              "          (0): InvertedResidual(\n",
              "            (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNormAct2d(\n",
              "              144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
              "            (bn2): BatchNormAct2d(\n",
              "              144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (aa): Identity()\n",
              "            (se): Identity()\n",
              "            (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNormAct2d(\n",
              "              32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): Identity()\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (1): InvertedResidual(\n",
              "            (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNormAct2d(\n",
              "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "            (bn2): BatchNormAct2d(\n",
              "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (aa): Identity()\n",
              "            (se): Identity()\n",
              "            (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNormAct2d(\n",
              "              32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): Identity()\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (2): InvertedResidual(\n",
              "            (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNormAct2d(\n",
              "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "            (bn2): BatchNormAct2d(\n",
              "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (aa): Identity()\n",
              "            (se): Identity()\n",
              "            (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNormAct2d(\n",
              "              32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): Identity()\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "        )\n",
              "        (3): Sequential(\n",
              "          (0): InvertedResidual(\n",
              "            (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNormAct2d(\n",
              "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
              "            (bn2): BatchNormAct2d(\n",
              "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (aa): Identity()\n",
              "            (se): Identity()\n",
              "            (conv_pwl): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNormAct2d(\n",
              "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): Identity()\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (1): InvertedResidual(\n",
              "            (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNormAct2d(\n",
              "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "            (bn2): BatchNormAct2d(\n",
              "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (aa): Identity()\n",
              "            (se): Identity()\n",
              "            (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNormAct2d(\n",
              "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): Identity()\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (2): InvertedResidual(\n",
              "            (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNormAct2d(\n",
              "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "            (bn2): BatchNormAct2d(\n",
              "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (aa): Identity()\n",
              "            (se): Identity()\n",
              "            (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNormAct2d(\n",
              "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): Identity()\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (3): InvertedResidual(\n",
              "            (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNormAct2d(\n",
              "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "            (bn2): BatchNormAct2d(\n",
              "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (aa): Identity()\n",
              "            (se): Identity()\n",
              "            (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNormAct2d(\n",
              "              64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): Identity()\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "        )\n",
              "        (4): Sequential(\n",
              "          (0): InvertedResidual(\n",
              "            (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNormAct2d(\n",
              "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "            (bn2): BatchNormAct2d(\n",
              "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (aa): Identity()\n",
              "            (se): Identity()\n",
              "            (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNormAct2d(\n",
              "              96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): Identity()\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (1): InvertedResidual(\n",
              "            (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNormAct2d(\n",
              "              576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "            (bn2): BatchNormAct2d(\n",
              "              576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (aa): Identity()\n",
              "            (se): Identity()\n",
              "            (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNormAct2d(\n",
              "              96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): Identity()\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (2): InvertedResidual(\n",
              "            (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNormAct2d(\n",
              "              576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "            (bn2): BatchNormAct2d(\n",
              "              576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (aa): Identity()\n",
              "            (se): Identity()\n",
              "            (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNormAct2d(\n",
              "              96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): Identity()\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "        )\n",
              "        (5): Sequential(\n",
              "          (0): InvertedResidual(\n",
              "            (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNormAct2d(\n",
              "              576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
              "            (bn2): BatchNormAct2d(\n",
              "              576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (aa): Identity()\n",
              "            (se): Identity()\n",
              "            (conv_pwl): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNormAct2d(\n",
              "              160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): Identity()\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (1): InvertedResidual(\n",
              "            (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNormAct2d(\n",
              "              960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "            (bn2): BatchNormAct2d(\n",
              "              960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (aa): Identity()\n",
              "            (se): Identity()\n",
              "            (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNormAct2d(\n",
              "              160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): Identity()\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (2): InvertedResidual(\n",
              "            (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNormAct2d(\n",
              "              960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "            (bn2): BatchNormAct2d(\n",
              "              960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (aa): Identity()\n",
              "            (se): Identity()\n",
              "            (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNormAct2d(\n",
              "              160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): Identity()\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "        )\n",
              "        (6): Sequential(\n",
              "          (0): InvertedResidual(\n",
              "            (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNormAct2d(\n",
              "              960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "            (bn2): BatchNormAct2d(\n",
              "              960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): ReLU6(inplace=True)\n",
              "            )\n",
              "            (aa): Identity()\n",
              "            (se): Identity()\n",
              "            (conv_pwl): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNormAct2d(\n",
              "              320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "              (drop): Identity()\n",
              "              (act): Identity()\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fpn): Fpn(\n",
              "    (latlayer2): Sequential(\n",
              "      (0): SeparableConv2d(\n",
              "        (conv1): Sequential(\n",
              "          (0): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=24, bias=False)\n",
              "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (pointwise): Conv2d(24, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (latlayer3): Sequential(\n",
              "      (0): SeparableConv2d(\n",
              "        (conv1): Sequential(\n",
              "          (0): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32, bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (pointwise): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (latlayer4): Sequential(\n",
              "      (0): SeparableConv2d(\n",
              "        (conv1): Sequential(\n",
              "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (pointwise): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (upsample3): ComplexUpsample(\n",
              "      (conv1): Sequential(\n",
              "        (0): SeparableConv2d(\n",
              "          (conv1): Sequential(\n",
              "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (pointwise): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        )\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): SeparableConv2d(\n",
              "          (conv1): Sequential(\n",
              "            (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (pointwise): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        )\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (upsample4): ComplexUpsample(\n",
              "      (conv1): Sequential(\n",
              "        (0): SeparableConv2d(\n",
              "          (conv1): Sequential(\n",
              "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (pointwise): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        )\n",
              "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): SeparableConv2d(\n",
              "          (conv1): Sequential(\n",
              "            (0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (pointwise): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        )\n",
              "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (upsample5): ComplexUpsample(\n",
              "      (conv1): Sequential(\n",
              "        (0): SeparableConv2d(\n",
              "          (conv1): Sequential(\n",
              "            (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
              "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (pointwise): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        )\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): SeparableConv2d(\n",
              "          (conv1): Sequential(\n",
              "            (0): Conv2d(320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False)\n",
              "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (pointwise): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        )\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head): CenterNetHead(\n",
              "    (cls): SeparableConv2d(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (pointwise): Conv2d(128, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (wh): SeparableConv2d(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (pointwise): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UiITT7GRmL_e"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqNGw083kowV",
        "outputId": "6e99968b-3c4f-4c2a-8129-40e29f806ba9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start Tracing\n",
            "End Tracing\n",
            "torch.Size([1, 10, 80, 80])\n",
            "torch.Size([1, 10, 80, 80])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:935: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  param_grad = param.grad\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10, 80, 80])\n",
            "torch.Size([1, 10, 80, 80])\n",
            "torch.Size([1, 10, 80, 80])\n",
            "torch.Size([1, 10, 80, 80])\n",
            "torch.Size([1, 10, 80, 80])\n",
            "torch.Size([1, 10, 80, 80])\n",
            "torch.Size([1, 10, 80, 80])\n",
            "torch.Size([1, 10, 80, 80])\n",
            "Total inference time for 100 runs: 2.80 seconds\n",
            "Average FPS: 35.68\n"
          ]
        }
      ],
      "source": [
        "batch_size = 1\n",
        "input_height = 320\n",
        "input_width = 320\n",
        "device = torch.device('cpu')\n",
        "model.to(device)\n",
        "dummy_input = torch.randn(batch_size, 3, input_height, input_width).to(device)\n",
        "print(\"Start Tracing\")\n",
        "model = torch.jit.trace(model, dummy_input)\n",
        "print(\"End Tracing\")\n",
        "\n",
        "# Create dummy input data\n",
        "# Quantize the model for faster CPU inference\n",
        "model_quantized = torch.quantization.quantize_dynamic(\n",
        "    model, {nn.Conv2d, nn.Linear}, dtype=torch.qint8\n",
        ")\n",
        "model_quantized.eval()\n",
        "model_quantized.to(device)\n",
        "\n",
        "\n",
        "\n",
        "# Warm-up runs (to exclude initialization overhead)\n",
        "with torch.no_grad():\n",
        "    for _ in range(10):\n",
        "        _ = model_quantized(dummy_input)\n",
        "        print(_[0].shape)\n",
        "\n",
        "# Timing settings\n",
        "num_runs = 100\n",
        "start_time = time.time()\n",
        "\n",
        "# Run the model multiple times and measure the total time\n",
        "with torch.no_grad():\n",
        "    for _ in range(num_runs):\n",
        "        outputs = model_quantized(dummy_input)\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "fps = num_runs / total_time\n",
        "\n",
        "print(f\"Total inference time for {num_runs} runs: {total_time:.2f} seconds\")\n",
        "print(f\"Average FPS: {fps:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crKHlkvCnse8",
        "outputId": "f2898468-6235-4e5a-c97a-c0c8f3991ea8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:timm.models._builder:Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
          ]
        }
      ],
      "source": [
        "model = CenterNet(10)\n",
        "model.eval()\n",
        "outputs = model(dummy_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0UuPEsw1koyt"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1741109787.755734   34223 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9961 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpzg441gkv/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpzg441gkv/assets\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "W0000 00:00:1741109792.719864   34223 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1741109792.719881   34223 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "2025-03-04 20:36:32.720315: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpzg441gkv\n",
            "2025-03-04 20:36:32.724959: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
            "2025-03-04 20:36:32.724994: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpzg441gkv\n",
            "I0000 00:00:1741109792.765325   34223 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n",
            "2025-03-04 20:36:32.771640: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
            "2025-03-04 20:36:33.121487: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpzg441gkv\n",
            "2025-03-04 20:36:33.200394: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 480083 microseconds.\n",
            "2025-03-04 20:36:33.256904: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2025-03-04 20:36:34.412304: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3893] Estimated count of arithmetic ops: 1.431 G  ops, equivalently 0.715 G  MACs\n"
          ]
        }
      ],
      "source": [
        "#If model is traced/scripted, reload the base model\n",
        "sample_inputs = (torch.randn(1, 3, 320, 320),)\n",
        "edge_model = ai_edge_torch.convert(model, sample_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vuRkWy18ko09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
          ]
        }
      ],
      "source": [
        "edge_output = edge_model(*sample_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL8UqsEXnQBt",
        "outputId": "b7221d68-8fb9-42f8-8b75-770eb3ad8d16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 10, 80, 80)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edge_output[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwbTTXyDnU2M",
        "outputId": "e6121466-153e-46cc-c06a-3ab3b902469b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 80, 80])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CcR-gYFko3G",
        "outputId": "eff1213a-37d2-4c45-dcc0-3bd59251ec19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Something wrong with Pytorch --> TfLite\n"
          ]
        }
      ],
      "source": [
        "if np.allclose(outputs[0].detach().numpy(), edge_output[0], atol=1e-5):\n",
        "    print(\"Inference result with Pytorch and TfLite was within tolerance\")\n",
        "else:\n",
        "    print(\"Something wrong with Pytorch --> TfLite\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsE6_UEFndB8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "l8v445cqko5O"
      },
      "outputs": [],
      "source": [
        "edge_model.export('mbv2_centernet_ltrb.tflite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JhXxhVqf2VA",
        "outputId": "af5f2c5d-cf9d-4b05-f96b-03c8b2b09a3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "49.951631328792566\n"
          ]
        }
      ],
      "source": [
        "avg_fps = 0.0\n",
        "n = 100\n",
        "for i in range(n):\n",
        "  f1 = time.time()\n",
        "  edge_output = edge_model(*sample_inputs)\n",
        "  f2 = time.time()\n",
        "  avg_fps += 1 / (f2-f1)\n",
        "\n",
        "print(avg_fps/n)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ai_edge_torch.quantize.quant_config import QuantConfig\n",
        "from torch.ao.quantization.quantize_pt2e import prepare_pt2e, convert_pt2e\n",
        "from torch._export import capture_pre_autograd_graph\n",
        "\n",
        "from ai_edge_torch.quantize.pt2e_quantizer import get_symmetric_quantization_config\n",
        "from ai_edge_torch.quantize.pt2e_quantizer import PT2EQuantizer\n",
        "from ai_edge_torch.quantize.quant_config import QuantConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0304 20:50:29.571539 34223 site-packages/torch/_export/__init__.py:64] +============================+\n",
            "W0304 20:50:29.572239 34223 site-packages/torch/_export/__init__.py:65] |     !!!   WARNING   !!!    |\n",
            "W0304 20:50:29.572787 34223 site-packages/torch/_export/__init__.py:66] +============================+\n",
            "W0304 20:50:29.573360 34223 site-packages/torch/_export/__init__.py:67] capture_pre_autograd_graph() is deprecated and doesn't provide any function guarantee moving forward.\n",
            "W0304 20:50:29.573709 34223 site-packages/torch/_export/__init__.py:68] Please switch to use torch.export.export_for_training instead.\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_1) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_2) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_3) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_4) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_5) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_6) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_7) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_8) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_9) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_10) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_11) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_12) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_13) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_14) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_15) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_16) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_17) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_18) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_19) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_20) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_21) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_22) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_23) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_24) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_25) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_26) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_27) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_28) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_29) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_30) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_31) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_32) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_33) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_34) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_35) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_36) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_37) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_38) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_39) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_40) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_41) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_42) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_43) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_44) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_45) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_46) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_47) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_48) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_49) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_50) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_51) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_52) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_53) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_54) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_55) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_56) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_57) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_58) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_59) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_60) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_61) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_62) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_63) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_64) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_65) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_66) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_67) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_68) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_69) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_70) on an already erased node\n",
            "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor([[[[0.0934, 0.0983, 0.0992,  ..., 0.1025, 0.0973, 0.1050],\n",
              "           [0.0980, 0.1011, 0.1018,  ..., 0.0944, 0.1026, 0.1046],\n",
              "           [0.0989, 0.1003, 0.1002,  ..., 0.0959, 0.1013, 0.1005],\n",
              "           ...,\n",
              "           [0.1007, 0.1016, 0.0947,  ..., 0.0977, 0.0986, 0.1015],\n",
              "           [0.0944, 0.0929, 0.1112,  ..., 0.1006, 0.1017, 0.1024],\n",
              "           [0.1013, 0.0961, 0.1015,  ..., 0.1072, 0.1029, 0.1022]],\n",
              " \n",
              "          [[0.0960, 0.0959, 0.1007,  ..., 0.0996, 0.0983, 0.0959],\n",
              "           [0.0992, 0.0943, 0.1036,  ..., 0.0941, 0.0933, 0.0958],\n",
              "           [0.1009, 0.0990, 0.1007,  ..., 0.1026, 0.0968, 0.0969],\n",
              "           ...,\n",
              "           [0.0997, 0.0986, 0.0955,  ..., 0.1026, 0.0998, 0.0975],\n",
              "           [0.0984, 0.1013, 0.1022,  ..., 0.0976, 0.0965, 0.0984],\n",
              "           [0.1005, 0.0934, 0.1056,  ..., 0.0992, 0.0969, 0.0990]],\n",
              " \n",
              "          [[0.0958, 0.0954, 0.0977,  ..., 0.0926, 0.0939, 0.0937],\n",
              "           [0.0926, 0.0890, 0.1007,  ..., 0.0993, 0.0937, 0.0968],\n",
              "           [0.0960, 0.0992, 0.1005,  ..., 0.1038, 0.0991, 0.0991],\n",
              "           ...,\n",
              "           [0.0912, 0.0955, 0.0991,  ..., 0.0897, 0.1021, 0.0922],\n",
              "           [0.0948, 0.0981, 0.0933,  ..., 0.0900, 0.0997, 0.0996],\n",
              "           [0.0949, 0.0921, 0.0943,  ..., 0.0934, 0.0946, 0.0951]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[0.1011, 0.1000, 0.0998,  ..., 0.1059, 0.1020, 0.1028],\n",
              "           [0.1034, 0.0996, 0.0981,  ..., 0.0972, 0.1032, 0.1082],\n",
              "           [0.1003, 0.0968, 0.0969,  ..., 0.0976, 0.1019, 0.1051],\n",
              "           ...,\n",
              "           [0.1005, 0.0985, 0.1051,  ..., 0.1045, 0.1062, 0.1074],\n",
              "           [0.0989, 0.0914, 0.1038,  ..., 0.1030, 0.1069, 0.1069],\n",
              "           [0.0969, 0.1027, 0.1025,  ..., 0.1053, 0.1054, 0.1045]],\n",
              " \n",
              "          [[0.1029, 0.1037, 0.1026,  ..., 0.1016, 0.1061, 0.1054],\n",
              "           [0.1024, 0.1122, 0.1083,  ..., 0.0974, 0.1024, 0.1074],\n",
              "           [0.0997, 0.1055, 0.1038,  ..., 0.1061, 0.0982, 0.0986],\n",
              "           ...,\n",
              "           [0.1019, 0.1071, 0.1125,  ..., 0.1047, 0.1010, 0.1096],\n",
              "           [0.1010, 0.1080, 0.1042,  ..., 0.0974, 0.1032, 0.1016],\n",
              "           [0.1007, 0.1060, 0.1070,  ..., 0.0999, 0.1075, 0.1032]],\n",
              " \n",
              "          [[0.1045, 0.1024, 0.1068,  ..., 0.1013, 0.1036, 0.1037],\n",
              "           [0.1023, 0.1072, 0.1090,  ..., 0.1059, 0.1042, 0.1082],\n",
              "           [0.1015, 0.1088, 0.1086,  ..., 0.1154, 0.1072, 0.1001],\n",
              "           ...,\n",
              "           [0.1046, 0.1088, 0.1129,  ..., 0.1134, 0.1135, 0.1070],\n",
              "           [0.1039, 0.1061, 0.1034,  ..., 0.0990, 0.1063, 0.1037],\n",
              "           [0.1009, 0.1044, 0.1000,  ..., 0.0979, 0.1020, 0.1022]]]],\n",
              "        grad_fn=<SigmoidBackward0>),\n",
              " tensor([[[[ 0.3610, -0.1441, -0.2070,  ...,  0.1988,  0.3242,  0.3285],\n",
              "           [ 0.5199,  0.2822,  0.8248,  ...,  0.7066,  0.9706,  0.8818],\n",
              "           [ 0.7959,  0.3027, -0.0676,  ...,  0.1055,  0.8386,  0.0084],\n",
              "           ...,\n",
              "           [ 0.8804,  0.7166,  0.8824,  ...,  0.7107,  1.2083,  0.2798],\n",
              "           [ 0.5539, -0.5068,  0.7727,  ...,  0.2107,  0.1506,  0.3648],\n",
              "           [ 0.1020,  1.5279,  0.4303,  ...,  0.2797, -0.0778,  0.2614]],\n",
              " \n",
              "          [[-0.2954, -1.4251, -1.1802,  ..., -1.2482, -1.6947, -0.7317],\n",
              "           [-0.5005, -1.6624, -0.3739,  ...,  0.2314, -0.4672, -1.0156],\n",
              "           [-0.3368, -1.2297, -1.1680,  ..., -1.2813, -0.5074, -1.7087],\n",
              "           ...,\n",
              "           [ 0.2305, -0.9491, -0.0651,  ...,  0.3862, -0.8583, -0.8206],\n",
              "           [-1.4655, -0.1450, -2.1313,  ..., -0.3765, -0.7200,  0.1530],\n",
              "           [-0.6184, -0.4852,  0.7428,  ...,  0.1995, -0.2740, -0.8214]],\n",
              " \n",
              "          [[-0.5232,  0.9696,  0.9498,  ...,  0.0107,  0.5199, -0.0472],\n",
              "           [-0.6228,  1.0697,  0.9071,  ...,  0.7211,  0.4256,  0.4105],\n",
              "           [-0.1403,  1.0347,  0.1705,  ...,  1.9977,  1.4053,  0.6904],\n",
              "           ...,\n",
              "           [ 0.4927, -0.0627, -0.1678,  ...,  0.8931,  0.7863,  0.2001],\n",
              "           [ 0.7546,  1.1838,  0.2115,  ...,  1.5315,  0.4517,  1.6140],\n",
              "           [-0.2142, -0.6539,  1.4874,  ...,  0.0998, -0.3896,  0.3929]],\n",
              " \n",
              "          [[-1.0761, -0.2946, -0.9786,  ..., -0.5624, -0.5603, -0.6749],\n",
              "           [-0.8865, -1.9356, -0.6656,  ...,  0.0262,  0.0126, -0.4803],\n",
              "           [-1.7576, -2.1966, -1.7533,  ..., -1.2693, -0.7301, -1.0808],\n",
              "           ...,\n",
              "           [-0.8158, -1.4494, -1.7773,  ..., -1.1618, -1.7368, -1.0963],\n",
              "           [-1.7488, -2.3557, -1.8334,  ...,  0.7729, -1.5152, -0.0279],\n",
              "           [-0.9020, -2.1802, -0.9351,  ...,  0.1950,  0.2957, -0.5613]]]],\n",
              "        grad_fn=<MulBackward0>))"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pt2e_quantizer = PT2EQuantizer().set_global(\n",
        "    get_symmetric_quantization_config(is_per_channel=True, is_dynamic=True)\n",
        ")\n",
        "sample_args = (torch.rand(1,3,320,320),)\n",
        "pt2e_torch_model = capture_pre_autograd_graph(model, sample_args)\n",
        "pt2e_torch_model = prepare_pt2e(pt2e_torch_model, pt2e_quantizer)\n",
        "pt2e_torch_model(*sample_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the prepared model to a quantized model\n",
        "pt2e_torch_model = convert_pt2e(pt2e_torch_model, fold_quantize=False)\n",
        "pt2e_torch_model = torch.ao.quantization.move_exported_model_to_eval(pt2e_torch_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Your model is converted in training mode. Please set the module in evaluation mode with `module.eval()` for better on-device performance and compatibility.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpocgk0xnt/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpocgk0xnt/assets\n",
            "W0000 00:00:1741110830.249532   34223 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1741110830.249547   34223 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "2025-03-04 20:53:50.249681: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpocgk0xnt\n",
            "2025-03-04 20:53:50.253350: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
            "2025-03-04 20:53:50.253376: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpocgk0xnt\n",
            "2025-03-04 20:53:50.286851: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
            "2025-03-04 20:53:50.545505: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpocgk0xnt\n",
            "2025-03-04 20:53:50.603771: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 354093 microseconds.\n",
            "2025-03-04 20:53:51.012561: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3893] Estimated count of arithmetic ops: 1.431 G  ops, equivalently 0.715 G  MACs\n"
          ]
        }
      ],
      "source": [
        "pt2e_drq_model = ai_edge_torch.convert(pt2e_torch_model, sample_args, quant_config=QuantConfig(pt2e_quantizer=pt2e_quantizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "pt2e_drq_model.export('pq_mbv2_centernet_ltrb.tflite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23.114237047021117\n"
          ]
        }
      ],
      "source": [
        "avg_fps = 0.0\n",
        "n = 100\n",
        "for i in range(n):\n",
        "  f1 = time.time()\n",
        "  pt2e_edge_output = pt2e_drq_model(*sample_args)\n",
        "  f2 = time.time()\n",
        "  avg_fps += 1 / (f2-f1)\n",
        "\n",
        "print(avg_fps/n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def representative_dataset_gen_from_array():\n",
        "    # Option 2: Using a numpy array of samples\n",
        "    # Create a small calibration dataset (replace with your actual data)\n",
        "    calibration_data = np.random.rand(25, 3,320, 320)  # Example for image data with 100 samples\n",
        "    \n",
        "    for i in range(len(calibration_data)):\n",
        "        sample = calibration_data[i:i+1]\n",
        "        yield [sample.astype(np.float32)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpqjrkkcyj/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpqjrkkcyj/assets\n",
            "W0000 00:00:1741111146.970063   34223 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1741111146.970080   34223 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "2025-03-04 20:59:06.970260: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpqjrkkcyj\n",
            "2025-03-04 20:59:06.975161: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
            "2025-03-04 20:59:06.975219: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpqjrkkcyj\n",
            "2025-03-04 20:59:07.026725: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
            "2025-03-04 20:59:07.395066: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpqjrkkcyj\n",
            "2025-03-04 20:59:07.485848: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 515591 microseconds.\n",
            "2025-03-04 20:59:08.820031: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3893] Estimated count of arithmetic ops: 1.431 G  ops, equivalently 0.715 G  MACs\n",
            "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n",
            "2025-03-04 20:59:14.027177: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3893] Estimated count of arithmetic ops: 1.431 G  ops, equivalently 0.715 G  MACs\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Pass TfLite Converter quantization flags to _ai_edge_converter_flags parameter.\n",
        "tfl_converter_flags = {'optimizations': [tf.lite.Optimize.DEFAULT],'target_spec.supported_ops' : [tf.lite.OpsSet.TFLITE_BUILTINS_INT8],'inference_input_type':tf.int8,'inference_output_type':tf.int8,\n",
        "                       'representative_dataset' :representative_dataset_gen_from_array }\n",
        "\n",
        "tfl_drq_model = ai_edge_torch.convert(\n",
        "    model, sample_args, _ai_edge_converter_flags=tfl_converter_flags\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "tfl_drq_model.export('mbv2_tflite_int8.tflite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "         [[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "         [[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]]]], dtype=torch.int8)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.rand((1,3,320,320)).to(torch.int8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "67.4330118359619\n"
          ]
        }
      ],
      "source": [
        "avg_fps = 0.0\n",
        "n = 100\n",
        "sample_int8 = torch.rand((1,3,320,320)).to(torch.int8)\n",
        "for i in range(n):\n",
        "  f1 = time.time()\n",
        "  int8_edge_output = tfl_drq_model(sample_int8)\n",
        "  f2 = time.time()\n",
        "  avg_fps += 1 / (f2-f1)\n",
        "\n",
        "print(avg_fps/n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openvino as ov "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dummy_input = torch.randn(1, 3, 320, 320)\n",
        "ovmodel =  ov.compile_model(ov.convert_model(model, example_input=dummy_input))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "158.9495103578814\n"
          ]
        }
      ],
      "source": [
        "avg_fps = 0.0\n",
        "n = 100\n",
        "dummy_input = torch.randn(1, 3, 320, 320)\n",
        "for i in range(n):\n",
        "  f1 = time.time()\n",
        "  out = ovmodel(dummy_input)\n",
        "  f2 = time.time()\n",
        "  avg_fps += 1 / (f2-f1)\n",
        "\n",
        "print(avg_fps/n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nncf\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RandomDataset(Dataset):\n",
        "    def __init__(self, size=100, shape=(3, 320, 320)):\n",
        "        self.size = size\n",
        "        self.shape = shape\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        # Generate random tensor in range [0, 1]\n",
        "        random_tensor = torch.rand(self.shape)\n",
        "        return random_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb9594f26faf41beaa4ef287946cccae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:nncf:Dataset contains only 13 samples, smaller than the requested subset size 300.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61d2584e03b3415f83ec4e71d145ac22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/nncf/torch/quantization/layers.py:344: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  return self._level_low.item()\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/nncf/torch/quantization/layers.py:352: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  return self._level_high.item()\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/jit/_trace.py:1306: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
            "Tensor-likes are not close!\n",
            "\n",
            "Mismatched elements: 62185 / 64000 (97.2%)\n",
            "Greatest absolute difference: 0.0016182512044906616 at index (0, 8, 38, 20) (up to 1e-05 allowed)\n",
            "Greatest relative difference: 0.01566274797813593 at index (0, 0, 4, 51) (up to 1e-05 allowed)\n",
            "  _check_trace(\n",
            "/home/rivian/anaconda3/envs/tf/lib/python3.9/site-packages/torch/jit/_trace.py:1306: TracerWarning: Output nr 2. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
            "Tensor-likes are not close!\n",
            "\n",
            "Mismatched elements: 25564 / 25600 (99.9%)\n",
            "Greatest absolute difference: 0.2747565507888794 at index (0, 1, 42, 20) (up to 1e-05 allowed)\n",
            "Greatest relative difference: 2036842.4069914538 at index (0, 1, 9, 54) (up to 1e-05 allowed)\n",
            "  _check_trace(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model successfully quantized to INT8 and saved as OpenVINO IR\n"
          ]
        }
      ],
      "source": [
        "calibration_dataset = RandomDataset(size=100, shape=(3, 320, 320))\n",
        "calibration_dataloader = DataLoader(calibration_dataset, batch_size=8)\n",
        "core = ov.Core()\n",
        "\n",
        "def transform_fn(data_item):\n",
        "    output = data_item\n",
        "    return output.float()\n",
        "\n",
        "calibration_dataset = nncf.Dataset(calibration_dataloader, transform_fn)\n",
        "# 5. Create quantized model\n",
        "quantized_model = nncf.quantize(\n",
        "    model=model,\n",
        "    calibration_dataset=calibration_dataset\n",
        ")\n",
        "\n",
        "# 7. Convert to OpenVINO IR\n",
        "dummy_input = torch.randn(1, 3, 320,320).float()\n",
        "quantized_model_ir = ov.convert_model(quantized_model, example_input=dummy_input, input=[-1,3,320,320])\n",
        "ov.save_model(quantized_model_ir, \"./int8.xml\")\n",
        "int8_compiled_model = core.compile_model(quantized_model_ir, 'CPU')\n",
        "\n",
        "print(\"Model successfully quantized to INT8 and saved as OpenVINO IR\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "429.92943314090473\n"
          ]
        }
      ],
      "source": [
        "avg_fps = 0.0\n",
        "n = 100\n",
        "dummy_input = torch.randn(1, 3, 320, 320)\n",
        "for i in range(n):\n",
        "  f1 = time.time()\n",
        "  out = int8_compiled_model(dummy_input)\n",
        "  f2 = time.time()\n",
        "  avg_fps += 1 / (f2-f1)\n",
        "\n",
        "print(avg_fps/n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
